{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb3f30b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-31T14:50:38.045731Z",
          "start_time": "2023-10-31T14:50:37.665733Z"
        },
        "id": "aeb3f30b"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from string import punctuation\n",
        "import spacy\n",
        "import optuna\n",
        "import torch\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense ,LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout,Input\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.layers import MaxPooling1D,Conv1D\n",
        "\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "tf.random.set_seed(66)\n",
        "np.random.seed(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cb0287a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:57.908409Z",
          "start_time": "2023-10-26T11:15:57.832163Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "4cb0287a",
        "outputId": "f48f4a0e-805e-48ab-f482-cf5bcf033f21"
      },
      "outputs": [],
      "source": [
        "df_train_val = pd.read_csv('review_train.csv')\n",
        "dic = pd.read_json('review_metadata.json',orient='index').reset_index()\n",
        "dic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02977803",
      "metadata": {
        "id": "02977803"
      },
      "source": [
        "# data inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca0bd26",
      "metadata": {
        "heading_collapsed": true,
        "id": "fca0bd26"
      },
      "source": [
        "## missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64cf6ab5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:57.923792Z",
          "start_time": "2023-10-26T11:15:57.909482Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "64cf6ab5",
        "outputId": "dc51dc19-a370-4764-aba2-483a127af341"
      },
      "outputs": [],
      "source": [
        "df_train_val.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c758782",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:57.985445Z",
          "start_time": "2023-10-26T11:15:57.925794Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "4c758782",
        "outputId": "766d5ad3-c0da-49d6-db13-f45887a6c2dc"
      },
      "outputs": [],
      "source": [
        "df_train_val.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf374a5a",
      "metadata": {
        "hidden": true,
        "id": "bf374a5a"
      },
      "source": [
        "### negative_reason                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db1adaa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:58.032076Z",
          "start_time": "2023-10-26T11:15:57.986930Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "hidden": true,
        "id": "1db1adaa",
        "outputId": "005d8fde-4447-4e6e-aa4d-15ef6fc21611"
      },
      "outputs": [],
      "source": [
        "missing_in_reason_s = df_train_val.loc[(pd.isnull(df_train_val['negative_reason_confidence']))]\n",
        "missing_in_reason_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ec14a0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:58.064083Z",
          "start_time": "2023-10-26T11:15:58.033308Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "c9ec14a0",
        "outputId": "9f08622a-5067-4707-e845-fa7d670384bb"
      },
      "outputs": [],
      "source": [
        "null_counts = df_train_val.groupby('airline_sentiment')['negative_reason'].apply(lambda x: x.isna().sum())\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "226274c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:58.110470Z",
          "start_time": "2023-10-26T11:15:58.065164Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "226274c7",
        "outputId": "07b52e03-566e-4643-d0af-b6aa2aef61cd"
      },
      "outputs": [],
      "source": [
        "all_counts =df_train_val['airline_sentiment'].value_counts()\n",
        "all_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae3f34a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:58.221558Z",
          "start_time": "2023-10-26T11:15:58.158597Z"
        },
        "hidden": true,
        "id": "0ae3f34a"
      },
      "outputs": [],
      "source": [
        "df_train_val['negative_reason_confidence'] = df_train_val['negative_reason_confidence'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0670f46",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:58.377047Z",
          "start_time": "2023-10-26T11:15:58.315452Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "e0670f46",
        "outputId": "03ba3d00-0b99-4263-ab39-1cf2c15be31d"
      },
      "outputs": [],
      "source": [
        "df_train_val.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0231e161",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:58.392825Z",
          "start_time": "2023-10-26T11:15:58.378116Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "0231e161",
        "outputId": "70541aee-a7b4-4e33-af5f-2684fd991c18"
      },
      "outputs": [],
      "source": [
        "df_train_val['review_city'].isnull().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111b13a5",
      "metadata": {
        "id": "111b13a5"
      },
      "source": [
        "# EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b9653ac",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:02.769505Z",
          "start_time": "2023-10-26T11:15:58.394310Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            ""
          ]
        },
        "id": "7b9653ac",
        "outputId": "ada7246f-416c-480f-d5d5-bb23b325b37a"
      },
      "outputs": [],
      "source": [
        "from dataprep.eda import plot\n",
        "plot(df_train_val, 'airline_sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ee133f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:03.128402Z",
          "start_time": "2023-10-26T11:16:02.770833Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            ""
          ]
        },
        "id": "c0ee133f",
        "outputId": "bf819351-a5ff-473a-bd30-3b6a4f63f5b5"
      },
      "outputs": [],
      "source": [
        "plot(df_train_val, 'airline_sentiment','sentiment_confidence')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f8b630",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:03.797315Z",
          "start_time": "2023-10-26T11:16:03.129848Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            ""
          ]
        },
        "id": "49f8b630",
        "outputId": "57dfd162-e29f-4b58-b567-bb4968a1bb78"
      },
      "outputs": [],
      "source": [
        "plot(df_train_val,'airline_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ce5ec18",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:04.033262Z",
          "start_time": "2023-10-26T11:16:03.799212Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "9ce5ec18",
        "outputId": "6c98557a-548b-4778-b820-b70ca6b4b42b"
      },
      "outputs": [],
      "source": [
        "plot(df_train_val, 'airline_sentiment','airline_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b2b62c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:05.385252Z",
          "start_time": "2023-10-26T11:16:04.034424Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            ""
          ]
        },
        "id": "f3b2b62c",
        "outputId": "40b651c3-b83b-4aa5-b8f5-43c2062eee8a"
      },
      "outputs": [],
      "source": [
        "plot(df_train_val, 'review_text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f60f6c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:06.077637Z",
          "start_time": "2023-10-26T11:16:05.387253Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            ""
          ]
        },
        "id": "11f60f6c",
        "outputId": "0e2d1d8f-c22a-4397-f7bb-516846ccf43d"
      },
      "outputs": [],
      "source": [
        "plot(df_train_val, 'negative_reason')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676c11e0",
      "metadata": {
        "id": "676c11e0",
        "outputId": "aa8edb8f-3db5-46b3-c241-7cd35ce2f1f3"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "positive_reviews = df_train_val[df_train_val['airline_sentiment'] == 'positive']\n",
        "\n",
        "# Combine the rows' review_text columns into one long string\n",
        "text = ' '.join(review for review in positive_reviews['review_text'])\n",
        "\n",
        "# Generate and display word clouds\n",
        "wordcloud = WordCloud(width=800, height=400, background_color ='white', min_font_size = 10).generate(text)\n",
        "\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.title(\"Positive WordCloud\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3817103",
      "metadata": {
        "id": "a3817103",
        "outputId": "9758dcb1-72dd-48d3-972f-0591b9172463"
      },
      "outputs": [],
      "source": [
        "negative_reviews = df_train_val[df_train_val['airline_sentiment'] == 'negative']\n",
        "\n",
        "# Combine the rows' review_text columns into one long string\n",
        "text = ' '.join(review for review in negative_reviews['review_text'])\n",
        "\n",
        "# Generate and display word clouds\n",
        "wordcloud = WordCloud(width=800, height=400, background_color ='white', min_font_size = 10).generate(text)\n",
        "\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.title(\"Negative WordCloud\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdc4061e",
      "metadata": {
        "id": "bdc4061e",
        "outputId": "be5eaace-347e-411b-ff34-b3c979e5dcea"
      },
      "outputs": [],
      "source": [
        "neutral_reviews = df_train_val[df_train_val['airline_sentiment'] == 'neutral']\n",
        "\n",
        "# Combine the rows' review_text columns into one long string\n",
        "text = ' '.join(review for review in neutral_reviews['review_text'])\n",
        "\n",
        "# Generate and display word clouds\n",
        "wordcloud = WordCloud(width=800, height=400, background_color ='white', min_font_size = 10).generate(text)\n",
        "\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.title(\"Neutral WordCloud\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2b8e91",
      "metadata": {
        "id": "ff2b8e91"
      },
      "source": [
        "# part B"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c56bec6",
      "metadata": {
        "id": "0c56bec6"
      },
      "source": [
        "### target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "966a884d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:06.093641Z",
          "start_time": "2023-10-26T11:16:06.079638Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "966a884d",
        "outputId": "9984fb54-0345-4b55-a6d8-6261a12ca9b1"
      },
      "outputs": [],
      "source": [
        "y = df_train_val['airline_sentiment']\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e8c711",
      "metadata": {
        "id": "a1e8c711"
      },
      "source": [
        "### review text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "586ca8b3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:06.204197Z",
          "start_time": "2023-10-26T11:16:06.141483Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "586ca8b3",
        "outputId": "ee57fd24-c385-4fa0-af6e-ddae4d7fbdad"
      },
      "outputs": [],
      "source": [
        "review = df_train_val['review_text'].str.lower().tolist()\n",
        "review"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9OIHmx-cF_Mx",
      "metadata": {
        "id": "9OIHmx-cF_Mx"
      },
      "source": [
        "text pre processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IY1r6-aC8ZPj",
      "metadata": {
        "id": "IY1r6-aC8ZPj"
      },
      "source": [
        "Stop words removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lU6tRKQTGert",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU6tRKQTGert",
        "outputId": "0cb52854-ccd2-4f06-a858-ebcf3c2aa097"
      },
      "outputs": [],
      "source": [
        "punctuations = list(punctuation)\n",
        "punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db48aa32",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:15:58.283124Z",
          "start_time": "2023-10-26T11:15:58.223564Z"
        },
        "id": "db48aa32"
      },
      "outputs": [],
      "source": [
        "## drop URL\n",
        "df_train_val['review_text'] = df_train_val['review_text'].str.replace(r'http\\S+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OXkZ3q9LioMP",
      "metadata": {
        "id": "OXkZ3q9LioMP"
      },
      "outputs": [],
      "source": [
        "#reference:https://medium.com/coinmonks/text-classifier-with-keras-tensorflow-using-recurrent-neural-networks-ad63dd5fc316\n",
        "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
        "def text_pre_process(sent, stemming=True, lemmatising=True,stop_words = None):\n",
        "  # Convert the text to lowercase and remove leading/trailing whitespaces\n",
        "  sent = str(sent).lower()\n",
        "  sent = sent.strip()\n",
        "\n",
        "  if punctuations is not None:\n",
        "    for punctuation in punctuations:\n",
        "      sent = sent.replace(punctuation, '')\n",
        "\n",
        "    # Tokenize\n",
        "    doc = spacy_nlp(sent)\n",
        "\n",
        "    # Lemmatizing\n",
        "    if lemmatising == True:\n",
        "        sent_list = [token.lemma_ for token in doc]\n",
        "    else:\n",
        "        sent_list = [token.text for token in doc]\n",
        "\n",
        "    # Stop word removal\n",
        "    if stop_words is not None:\n",
        "        sent_list = [c for c in sent_list if c not in stop_words]\n",
        "\n",
        "    sent = \" \".join(sent_list)\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ikCB4nEpR-R",
      "metadata": {
        "id": "6ikCB4nEpR-R"
      },
      "outputs": [],
      "source": [
        "stop_words = nltk.corpus.stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aezmvy5nKVR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "2aezmvy5nKVR",
        "outputId": "2244a2f4-5922-4493-b325-09f8e8abf2ad"
      },
      "outputs": [],
      "source": [
        "df_train_val['processed_text_review'] = df_train_val['review_text'].apply(\n",
        "    lambda x: text_pre_process(x,stemming=True, lemmatising=True,stop_words = stop_words))\n",
        "df_train_val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NSzBeL234za1",
      "metadata": {
        "id": "NSzBeL234za1"
      },
      "outputs": [],
      "source": [
        "## Train test split\n",
        "### split before encoding to mitigate data leakage\n",
        "train_indices, val_indices = train_test_split(np.array(df_train_val.index), test_size=0.2, random_state=6)\n",
        "\n",
        "df_train = df_train_val.loc[train_indices].copy()\n",
        "df_val = df_train_val.loc[val_indices].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rS8qv5at6vGX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS8qv5at6vGX",
        "outputId": "6c086b57-6f67-4f46-bb81-60f95a6ce4a4"
      },
      "outputs": [],
      "source": [
        "print('shape of train set:', df_train.shape)\n",
        "print('shape of validation set:', df_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YKILjMvwpAX1",
      "metadata": {
        "id": "YKILjMvwpAX1"
      },
      "outputs": [],
      "source": [
        "x_train = df_train['processed_text_review']\n",
        "x_val = df_val['processed_text_review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3HLzli9x8TUB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HLzli9x8TUB",
        "outputId": "00fe8ad0-889f-4aed-c98e-5e22c151bbb3"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uncm6GKG9TEL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uncm6GKG9TEL",
        "outputId": "0914d3c1-2d31-430b-995f-5d7a595917f9"
      },
      "outputs": [],
      "source": [
        "y_train = df_train['airline_sentiment']\n",
        "y_val = df_val['airline_sentiment']\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GD1w9EY38wPb",
      "metadata": {
        "id": "GD1w9EY38wPb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_train_array = np.array(y_train).reshape(-1, 1)\n",
        "y_val_array = np.array(y_val).reshape(-1, 1)\n",
        "\n",
        "\n",
        "y_train = encoder.fit_transform(y_train_array)\n",
        "y_val = encoder.transform(y_val_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AZIrdc6v9vd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZIrdc6v9vd5",
        "outputId": "ed3936b3-0e81-47ca-ad70-a4acdd169adf"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8517204c",
      "metadata": {
        "id": "8517204c"
      },
      "source": [
        "### TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4b9379",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:06.235500Z",
          "start_time": "2023-10-26T11:16:06.205291Z"
        },
        "id": "cc4b9379"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417647b4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:06.409421Z",
          "start_time": "2023-10-26T11:16:06.236926Z"
        },
        "id": "417647b4"
      },
      "outputs": [],
      "source": [
        "vectorizer_tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "\n",
        "x_tfidf_train = vectorizer_tfidf.fit_transform(x_train)\n",
        "x_tfidf_val = vectorizer_tfidf.transform(x_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59cb9ec4",
      "metadata": {
        "id": "59cb9ec4"
      },
      "source": [
        "#### random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0f8455",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:16:06.489428Z",
          "start_time": "2023-10-26T11:16:06.442429Z"
        },
        "id": "5e0f8455"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=6, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eedb9f8e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:19:10.274479Z",
          "start_time": "2023-10-26T11:16:06.539602Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eedb9f8e",
        "outputId": "4c39e7e8-9a45-4781-acf3-0def1a1cdc57",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    criterion = 'gini'\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 500, step = 10 )\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators,\n",
        "                                   max_depth = max_depth,\n",
        "                                   min_samples_leaf= min_samples_leaf,\n",
        "                                   criterion=criterion,\n",
        "                                   random_state=0\n",
        "                                 )\n",
        "\n",
        "    scores = cross_val_score(model, x_tfidf_train, y_train, cv=cv, scoring='accuracy')\n",
        "    accuracy = np.mean(scores)\n",
        "\n",
        "    return 1 - accuracy\n",
        "\n",
        "sampler = TPESampler(seed=0)\n",
        "study = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "study.optimize(objective, n_trials = 100, timeout = 7200, n_jobs= -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d3e1b2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:19:19.452919Z",
          "start_time": "2023-10-26T11:19:19.445591Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8d3e1b2",
        "outputId": "416f94af-822c-48b2-e4c5-cdd07e29d0e3"
      },
      "outputs": [],
      "source": [
        "params_rf = study.best_params\n",
        "params_rf\n",
        "#{'max_depth': 5, 'n_estimators': 280, 'min_samples_leaf': 7}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9864c223",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:19:20.452748Z",
          "start_time": "2023-10-26T11:19:20.323917Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "9864c223",
        "outputId": "7752d355-ec0f-4763-f941-9bd304466981"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(**params_rf,n_jobs = -1,random_state=0)\n",
        "rf.fit(x_tfidf_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wFY2oXgMMWLI",
      "metadata": {
        "id": "wFY2oXgMMWLI",
        "outputId": "2fd3e713-8497-4e14-ec93-ea22d0b6cdb5"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred_rf = rf.predict(x_tfidf_val)\n",
        "y_pred_classes_rf = y_pred_rf.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "\n",
        "report = classification_report(y_val.argmax(axis=-1), y_pred_classes_rf, digits=3)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06b665b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:19:20.642974Z",
          "start_time": "2023-10-26T11:19:20.616975Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f06b665b",
        "outputId": "08e696bb-02c8-4106-e4a6-a80845132268"
      },
      "outputs": [],
      "source": [
        "y_pred_tfidf_rf = rf.predict(x_tfidf_val)\n",
        "accuracy_tfidf_rf = accuracy_score(y_val, y_pred_tfidf_rf).round(3)\n",
        "print(\"Accuracy:\", accuracy_tfidf_rf)\n",
        "# Accuracy: 0.604"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfdf22af",
      "metadata": {
        "id": "cfdf22af"
      },
      "source": [
        "#### gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9702ccd2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:30:39.024427Z",
          "start_time": "2023-10-26T11:22:24.256355Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "9702ccd2",
        "outputId": "8aee0f17-93bf-4cd9-bceb-3c5ed63d1393"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "xgb_classifier = xgb.XGBClassifier()\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.01, 0.05],\n",
        "    'n_estimators': np.arange(50, 500, 10),\n",
        "    'max_depth': np.arange(1, 20, 1),\n",
        "}\n",
        "\n",
        "xgb = RandomizedSearchCV(\n",
        "    estimator=xgb_classifier,\n",
        "    param_distributions=param_grid,\n",
        "    n_jobs=-1,\n",
        "    cv=cv,\n",
        "    scoring='accuracy',\n",
        "    verbose=5,\n",
        "    return_train_score=True,\n",
        "    random_state = 6\n",
        ")\n",
        "\n",
        "xgb.fit(x_tfidf_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MCKeh-rePj2Y",
      "metadata": {
        "id": "MCKeh-rePj2Y",
        "outputId": "4b38c140-fd4b-4fd7-be26-68d4b870e53c"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred_xgb = xgb.predict(x_tfidf_val)\n",
        "y_pred_classes_xgb = y_pred_xgb.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "report = classification_report(y_val.argmax(axis=-1), y_pred_classes_xgb, digits=3)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e0b513",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:30:54.647068Z",
          "start_time": "2023-10-26T11:30:54.632065Z"
        },
        "id": "14e0b513",
        "outputId": "ce565102-27ff-4f0d-ac6f-d8d13f53bdf0"
      },
      "outputs": [],
      "source": [
        "params_xgb = xgb.best_params_\n",
        "print(\"Hyperparameters:\", params_xgb)\n",
        "\n",
        "y_pred_tfidf_xgb = xgb.predict(x_tfidf_val)\n",
        "accuracy_tfidf_xgb = accuracy_score(y_val, y_pred_tfidf_xgb).round(3)\n",
        "print(\"Accuracy:\", accuracy_tfidf_xgb)\n",
        "#Hyperparameters: {'n_estimators': 430, 'max_depth': 19, 'learning_rate': 0.1}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gu_qdvyxLKpn",
      "metadata": {
        "id": "Gu_qdvyxLKpn"
      },
      "source": [
        "TASK C RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6OKfJSo7yqPy",
      "metadata": {
        "id": "6OKfJSo7yqPy"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# build a tokenizer with spacy\n",
        "tokenizer = get_tokenizer('spacy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y-Ghi7z-j5qu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-Ghi7z-j5qu",
        "outputId": "bd139e4f-d6cf-45e6-f2b7-faa95b387bd4"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import vocab\n",
        "from collections import Counter\n",
        "\n",
        "#Select the words occurred more than three times\n",
        "counter = Counter()\n",
        "for i in df_train_val['processed_text_review']:\n",
        "  counter.update(tokenizer(i))\n",
        "\n",
        "vocabulary = vocab(counter, min_freq=3)\n",
        "vocabulary.set_default_index(0)\n",
        "\n",
        "len(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SiVpHzH84qfH",
      "metadata": {
        "id": "SiVpHzH84qfH"
      },
      "outputs": [],
      "source": [
        "def sent_encode(docs,vocabulary):\n",
        "    encoded_docs = []\n",
        "    for doc in docs:\n",
        "        tokens = tokenizer(doc)\n",
        "        encoded_doc = [vocabulary[token] for token in tokens if token in vocabulary]\n",
        "        encoded_docs.append(encoded_doc)\n",
        "    return encoded_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gDkLY2Hux_eW",
      "metadata": {
        "id": "gDkLY2Hux_eW"
      },
      "outputs": [],
      "source": [
        "x_rnn_tokenized_train = sent_encode(x_train,vocabulary)\n",
        "x_rnn_tokenized_val = sent_encode(x_val,vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uUt_EjoNmr7C",
      "metadata": {
        "id": "uUt_EjoNmr7C"
      },
      "outputs": [],
      "source": [
        "sequence_length= np.max([len(s) for s in x_rnn_tokenized_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ezJsc5iTi3p3",
      "metadata": {
        "id": "ezJsc5iTi3p3"
      },
      "outputs": [],
      "source": [
        "# padding output as np array\n",
        "def padding(sents, sequence_length):\n",
        "    sent_padded = []\n",
        "    for sent in sents:\n",
        "        if len(sent) < sequence_length:\n",
        "            padding_size = sequence_length - len(sent)\n",
        "            padding = torch.zeros(padding_size, dtype=torch.long)\n",
        "            padded_sent = torch.cat((sent, padding))\n",
        "        elif len(sent) > sequence_length:\n",
        "            padded_sent = sent[:sequence_length]\n",
        "        else:\n",
        "            padded_sent = sent\n",
        "        sent_padded.append(padded_sent)\n",
        "    padded_array = np.array([sent.numpy() for sent in sent_padded])\n",
        "\n",
        "    return padded_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YjElSAcC1QYH",
      "metadata": {
        "id": "YjElSAcC1QYH"
      },
      "outputs": [],
      "source": [
        "x_rnn_tokenized_train = [torch.tensor(sent, dtype=torch.long) for sent in x_rnn_tokenized_train]\n",
        "x_rnn_tokenized_val = [torch.tensor(sent, dtype=torch.long) for sent in x_rnn_tokenized_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fLNWXgIHtoKB",
      "metadata": {
        "id": "fLNWXgIHtoKB"
      },
      "outputs": [],
      "source": [
        "x_rnn_encoded_train=padding(x_rnn_tokenized_train,sequence_length)\n",
        "x_rnn_encoded_val=padding(x_rnn_tokenized_val,sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vTNwdqrLt6W5",
      "metadata": {
        "id": "vTNwdqrLt6W5"
      },
      "outputs": [],
      "source": [
        "sequence_length = sequence_length\n",
        "vocab_size = len(vocabulary)#\n",
        "n_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prYx3_4hPFcZ",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "556872bad7e8463f8273d261679b4e95"
          ]
        },
        "id": "prYx3_4hPFcZ",
        "outputId": "8123602e-13ce-424c-a5f6-9cc6cbdca82f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    rnn_units = int(trial.suggest_categorical('rnn_units', [2**i for i in range(5, 9)]))# 32, 256\n",
        "    embedding_dim = int(trial.suggest_categorical('embedding_dim', [2**i for i in range(5, 9)]))# 32, 256\n",
        "    learning_rate = float(trial.suggest_categorical('learning_rate', [10**i for i in range(-6, -1)]))\n",
        "\n",
        "\n",
        "    early_stopping = EarlyStopping( monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length))\n",
        "    model.add(SimpleRNN(rnn_units))\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_rnn_encoded_train, y_train, epochs=20, validation_data=(x_rnn_encoded_val, y_val), batch_size=64, callbacks = [early_stopping], verbose=0)\n",
        "\n",
        "    val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=6))\n",
        "study.optimize(objective, n_trials= 50, timeout = 1200000, n_jobs= -1, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D-a-L675PI_t",
      "metadata": {
        "id": "D-a-L675PI_t",
        "outputId": "16dcc374-e988-402a-ac5d-cff9b9d6c813"
      },
      "outputs": [],
      "source": [
        "best_params = study.best_params\n",
        "best_params\n",
        "#{'rnn_units': 256, 'embedding_dim': 128, 'learning_rate': 1e-05}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jdhbf1bAPNfC",
      "metadata": {
        "id": "Jdhbf1bAPNfC"
      },
      "outputs": [],
      "source": [
        "best_rnn_units = best_params['rnn_units']\n",
        "best_learning_rate = best_params['learning_rate']\n",
        "best_embedding_dim = best_params['embedding_dim']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RphrMGgyP--p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "RphrMGgyP--p",
        "outputId": "0f7053f7-7978-47b3-ad47-ce2a9f7d5104"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping( monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "best_rnn_model = Sequential()\n",
        "best_rnn_model.add(Embedding(input_dim=vocab_size, output_dim=best_embedding_dim, input_length=sequence_length))\n",
        "best_rnn_model.add(SimpleRNN(best_rnn_units, kernel_regularizer=l2(0.01)))\n",
        "best_rnn_model.add(Dropout(0.2))\n",
        "best_rnn_model.add(Dense(n_classes, activation='softmax',kernel_regularizer=l2(0.01)))\n",
        "best_rnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history =best_rnn_model.fit(x_rnn_encoded_train, y_train, epochs=150, validation_data=(x_rnn_encoded_val, y_val), batch_size=64, callbacks = [early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a944PupWxcj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a944PupWxcj",
        "outputId": "992da7a8-c00d-4714-83bd-cff3773e03b0"
      },
      "outputs": [],
      "source": [
        "best_rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IZyJ5UJZRHW3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "IZyJ5UJZRHW3",
        "outputId": "9598ac83-6220-467a-cd0b-461fa9d29aaa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "ax[0].set(title='Loss')\n",
        "ax[0].plot(history.history['loss'], label='Training')\n",
        "ax[0].plot(history.history['val_loss'], label='Validation')\n",
        "ax[0].legend(loc=\"upper right\")\n",
        "\n",
        "ax[1].set(title='Accuracy')\n",
        "ax[1].plot(history.history['accuracy'], label='Training')\n",
        "ax[1].plot(history.history['val_accuracy'], label='Validation')\n",
        "ax[1].legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4qg99QhWx2Wz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qg99QhWx2Wz",
        "outputId": "13d4c81b-a157-4fc8-d002-15c32f709b24"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = best_rnn_model.predict(x_rnn_encoded_val)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "\n",
        "report = classification_report(y_val.argmax(axis=-1), y_pred_classes, digits=3)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pNRfk_onu14i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNRfk_onu14i",
        "outputId": "62ddfc12-a77f-4811-fd03-2376aff3798e"
      },
      "outputs": [],
      "source": [
        "accuracy_rnn = history.history['val_accuracy'][-1]\n",
        "print('Accuracy Training data: {:.1%}'.format(history.history['accuracy'][-1]))\n",
        "print('Accuracy Test data: {:.1%}'.format(history.history['val_accuracy'][-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2344b763",
      "metadata": {
        "id": "2344b763"
      },
      "source": [
        "### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e954dbb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-26T11:19:10.669041Z",
          "start_time": "2023-10-26T11:19:10.669041Z"
        },
        "id": "9e954dbb"
      },
      "outputs": [],
      "source": [
        "# read glove vector\n",
        "# reference: https://towardsdatascience.com/sentiment-analysis-using-lstm-and-glove-embeddings-99223a87fe8e\n",
        "def glove_emb(glove_file):\n",
        "  glove_embeddings = {}\n",
        "\n",
        "  with open(glove_file, 'r', encoding='utf-8') as file:\n",
        "      for line in file:\n",
        "          parts = line.strip().split()\n",
        "          word = parts[0]\n",
        "          embedding = np.array(parts[1:], dtype=float)\n",
        "          glove_embeddings[word] = embedding\n",
        "  return glove_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0453e1a",
      "metadata": {
        "id": "d0453e1a"
      },
      "outputs": [],
      "source": [
        "glove_vac = glove_emb('glove.6B.300d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jTV3xL1Q2ow8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTV3xL1Q2ow8",
        "outputId": "f1700409-0c66-488d-c80e-c593a7026ee8"
      },
      "outputs": [],
      "source": [
        "# create glove matrix d:len(vocabulary) X 300\n",
        "glove_dim = 300 # dimension of glove\n",
        "vocab_lenth = len(vocabulary)\n",
        "emb_matrix = np.zeros((vocab_lenth, glove_dim))\n",
        "\n",
        "itos = vocabulary.get_itos()\n",
        "for i, word in enumerate(itos):\n",
        "  if word in glove_vac:\n",
        "    emb_matrix[i] = glove_vac[word]\n",
        "  else:\n",
        "    emb_matrix[i] = [0]*300\n",
        "\n",
        "emb_matrix = torch.FloatTensor(emb_matrix)\n",
        "emb_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xN43h-uI4uRT",
      "metadata": {
        "id": "xN43h-uI4uRT"
      },
      "outputs": [],
      "source": [
        "x_glove_train = x_rnn_encoded_train\n",
        "x_glove_val = x_rnn_encoded_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R_qSHThG80m9",
      "metadata": {
        "id": "R_qSHThG80m9"
      },
      "outputs": [],
      "source": [
        "### hyperparameter sitting\n",
        "embedding_dim = glove_dim\n",
        "input_dim = vocab_lenth\n",
        "weight = [emb_matrix]\n",
        "\n",
        "rnn_units = 16\n",
        "sequence_length = sequence_length\n",
        "vocab_size = len(vocabulary)#\n",
        "n_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vChIS4Lm6oFt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vChIS4Lm6oFt",
        "outputId": "ee1709ec-9c7f-4b73-f091-3c24c1314dba"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping( monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "glove_rnn_model = Sequential()\n",
        "glove_rnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=weight, trainable=False))\n",
        "glove_rnn_model.add(SimpleRNN(rnn_units))\n",
        "glove_rnn_model.add(Dropout(0.2))\n",
        "glove_rnn_model.add(Dense(n_classes, activation='softmax'))\n",
        "glove_rnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history_glove = glove_rnn_model.fit(x_glove_train, y_train, epochs=150, validation_data=(x_glove_val, y_val), batch_size=64, callbacks = [early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rgs9OEHAATyP",
      "metadata": {
        "id": "Rgs9OEHAATyP",
        "outputId": "580f1e0b-66b3-4222-9c71-26d273f254d5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "ax[0].set(title='Loss')\n",
        "ax[0].plot(history_glove.history['loss'], label='Training')\n",
        "ax[0].plot(history_glove.history['val_loss'], label='Validation')\n",
        "ax[0].legend(loc=\"upper right\")\n",
        "\n",
        "ax[1].set(title='Accuracy')\n",
        "ax[1].plot(history_glove.history['accuracy'], label='Training')\n",
        "ax[1].plot(history_glove.history['val_accuracy'], label='Validation')\n",
        "ax[1].legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70bdd8f9",
      "metadata": {
        "id": "70bdd8f9",
        "outputId": "91d1e83f-1589-4a37-89ba-4cf17a372922"
      },
      "outputs": [],
      "source": [
        "y_pred_glove = glove_rnn_model.predict(x_glove_val)\n",
        "y_pred_classes_glove = y_pred_glove.argmax(axis=-1) # For multi-class classification\n",
        "\n",
        "\n",
        "report_glove = classification_report(y_val.argmax(axis=-1), y_pred_classes_glove, digits=3)\n",
        "print(report_glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kyYJhAIdn7ww",
      "metadata": {
        "id": "kyYJhAIdn7ww"
      },
      "source": [
        "Task E\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KVdW9W5ojaMs",
      "metadata": {
        "id": "KVdW9W5ojaMs"
      },
      "outputs": [],
      "source": [
        "embedding_dim = glove_dim\n",
        "weight = [emb_matrix]\n",
        "\n",
        "rnn_units = 128\n",
        "vocab_size = len(vocabulary)#\n",
        "n_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vfI-a9WqP1lu",
      "metadata": {
        "id": "vfI-a9WqP1lu"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=15,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "def leaky_relu_e(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Da-SHpmSP4i3",
      "metadata": {
        "id": "Da-SHpmSP4i3",
        "outputId": "850ca034-56b5-4671-e2e4-e800fb8cd7cc"
      },
      "outputs": [],
      "source": [
        "# try1_model = Sequential()\n",
        "# try1_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=weight, trainable=False))\n",
        "# try1_model.add(SimpleRNN(rnn_units,activation = leaky_relu_e))\n",
        "# try1_model.add(Dropout(0.2))\n",
        "# try1_model.add(Dense(n_classes, activation='softmax'))\n",
        "# try1_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# history_try1 = try1_model.fit(x_glove_train, y_train, epochs=100, validation_data=(x_glove_val, y_val), batch_size=16,\n",
        "#                               callbacks = [early_stopping]\n",
        "#                                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KILdvzVF8-uA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KILdvzVF8-uA",
        "outputId": "ceae7341-7843-4926-c59a-b54461d3803f"
      },
      "outputs": [],
      "source": [
        "# y_pred_try1 = try1_model.predict(x_glove_val)\n",
        "# y_pred_classes_try1 = y_pred_try1.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "\n",
        "# report_try1 = classification_report(y_val.argmax(axis=-1), y_pred_classes_try1, digits=3)\n",
        "# print(report_try1)\n",
        "'''\n",
        "87/87 [==============================] - 4s 50ms/step\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0      0.814     0.879     0.845      1662\n",
        "           1      0.530     0.502     0.516       625\n",
        "           2      0.740     0.579     0.650       466\n",
        "\n",
        "    accuracy                          0.743      2753\n",
        "   macro avg      0.694     0.654     0.670      2753\n",
        "weighted avg      0.737     0.743     0.737      2753\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f4acaa",
      "metadata": {
        "id": "c6f4acaa"
      },
      "source": [
        "trial 2 using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72cdb6aa",
      "metadata": {
        "id": "72cdb6aa",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# ### lstm\n",
        "# try2_model = Sequential()\n",
        "# try2_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=weight, trainable=False))\n",
        "# try2_model.add(LSTM(rnn_units))\n",
        "# try2_model.add(Dropout(0.2))\n",
        "# try2_model.add(Dense(n_classes, activation='softmax'))\n",
        "# try2_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# history_try2 = try2_model.fit(x_glove_train, y_train, epochs=100,\n",
        "#                       validation_data=(x_glove_val, y_val), batch_size=16,\n",
        "#                       callbacks = [early_stopping]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac69344",
      "metadata": {
        "id": "dac69344",
        "outputId": "d3a91a08-b483-40d2-b353-8c5ac3441140"
      },
      "outputs": [],
      "source": [
        "# y_pred_try2 = try2_model.predict(x_glove_val)\n",
        "# y_pred_classes_try2 = y_pred_try2.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "\n",
        "# report_try2 = classification_report(y_val.argmax(axis=-1), y_pred_classes_try2, digits=3)\n",
        "# print(report_try2)\n",
        "'''\n",
        "87/87 [==============================] - 5s 52ms/step\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0      0.738     0.945     0.829      1662\n",
        "           1      0.661     0.293     0.406       625\n",
        "           2      0.772     0.573     0.658       466\n",
        "\n",
        "    accuracy                          0.734      2753\n",
        "   macro avg      0.723     0.604     0.631      2753\n",
        "weighted avg      0.726     0.734     0.704      2753\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09995ff",
      "metadata": {
        "id": "b09995ff"
      },
      "source": [
        "trail 3 using bi LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1420c4a5",
      "metadata": {
        "id": "1420c4a5",
        "outputId": "4d482b6b-a2d0-48a8-f12b-92e64ba6d006",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#### bid lstm\n",
        "\n",
        "try3_model = Sequential()\n",
        "try3_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=weight, trainable=False))\n",
        "try3_model.add(Bidirectional(LSTM(rnn_units, return_sequences=False),\n",
        "                            input_shape=(sequence_length, embedding_dim)))\n",
        "try3_model.add(Dropout(0.2))\n",
        "try3_model.add(Dense(n_classes, activation='softmax'))\n",
        "try3_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history_try3 = try3_model.fit(x_glove_train, y_train, epochs=100, validation_data=(x_glove_val, y_val), batch_size=16,\n",
        "                              callbacks = [early_stopping]\n",
        "                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c327e54b",
      "metadata": {
        "id": "c327e54b",
        "outputId": "d47118da-8098-483c-9317-01a06a047621"
      },
      "outputs": [],
      "source": [
        "y_pred_try3 = try3_model.predict(x_glove_val)\n",
        "y_pred_classes_try3 = y_pred_try3.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "report_try3 = classification_report(y_val.argmax(axis=-1), y_pred_classes_try3, digits=3)\n",
        "print(report_try3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4171ed03",
      "metadata": {
        "id": "4171ed03"
      },
      "source": [
        "trail 4 bi LSTM with CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a25e0254",
      "metadata": {
        "id": "a25e0254",
        "outputId": "d294392b-1178-47bf-c82f-3da3b0bcfd1e"
      },
      "outputs": [],
      "source": [
        "# try4_model = Sequential()\n",
        "# try4_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=weight, trainable=False))\n",
        "# try4_model.add(Conv1D(filters=32, kernel_size=3, padding='same'))\n",
        "# try4_model.add(MaxPooling1D(pool_size=2))\n",
        "# try4_model.add(Bidirectional(LSTM(rnn_units, return_sequences=False),\n",
        "#                             input_shape=(sequence_length, embedding_dim)))\n",
        "# try4_model.add(Dropout(0.2))\n",
        "# try4_model.add(Dense(n_classes, activation='softmax'))\n",
        "# try4_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
        "#                    loss='categorical_crossentropy',\n",
        "#                    metrics=['accuracy'])\n",
        "# history_try4 = try4_model.fit(x_glove_train, y_train, epochs=100, validation_data=(x_glove_val, y_val), batch_size=16,\n",
        "#                               callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d2f7fa",
      "metadata": {
        "id": "94d2f7fa",
        "outputId": "2930e870-8ada-4e8a-ee39-2e8fa8953a4f"
      },
      "outputs": [],
      "source": [
        "# try4_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a8952f8",
      "metadata": {
        "id": "8a8952f8",
        "outputId": "c5921d2a-9be9-492b-d3d4-be840fe5f1be"
      },
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "# ax[0].set(title='Loss')\n",
        "# ax[0].plot(history_try4.history['loss'], label='Training')\n",
        "# ax[0].plot(history_try4.history['val_loss'], label='Validation')\n",
        "# ax[0].legend(loc=\"upper right\")\n",
        "\n",
        "# ax[1].set(title='Accuracy')\n",
        "# ax[1].plot(history_try4.history['accuracy'], label='Training')\n",
        "# ax[1].plot(history_try4.history['val_accuracy'], label='Validation')\n",
        "# ax[1].legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71925a8f",
      "metadata": {
        "id": "71925a8f",
        "outputId": "d28c6603-6476-4836-c4c9-7f488b91665a"
      },
      "outputs": [],
      "source": [
        "# y_pred_try4 = try4_model.predict(x_glove_val)\n",
        "# y_pred_classes_try4 = y_pred_try4.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "\n",
        "# report_try4 = classification_report(y_val.argmax(axis=-1), y_pred_classes_try4, digits=3)\n",
        "# print(report_try4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46994970",
      "metadata": {
        "id": "46994970",
        "outputId": "ee48cbf4-ba4b-4104-b031-1a8b501991ad"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# # Compare and find the best model from task E\n",
        "\n",
        "# models = [(\"rnn_leakyrelu\", try1_model), (\"LSTM\", try2_model), (\"BiLSTM\", try3_model), (\"BiLSTM_CNN\", try4_model)]\n",
        "\n",
        "# for model_name, model in models:\n",
        "\n",
        "#     predictions = model.predict(x_glove_val)\n",
        "#     y_val_indices = y_val.argmax(axis=1)\n",
        "#     predictions_indices = predictions.argmax(axis=1)\n",
        "\n",
        "#     f1 = round(f1_score(y_val_indices, predictions_indices, average='macro'), 3)\n",
        "#     accuracy = round(accuracy_score(y_val_indices, predictions_indices), 3)\n",
        "\n",
        "#     print(f\"Model {model_name}:\")\n",
        "#     print(f\"Macro Avg F1 Score: {f1}\")\n",
        "#     print(f\"Validation Accuracy: {accuracy}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bda5f61",
      "metadata": {
        "id": "7bda5f61",
        "outputId": "15ecccaf-799f-4f9f-9704-de53436d42d0"
      },
      "outputs": [],
      "source": [
        "# # Compare and find the best model from all tasks\n",
        "\n",
        "# models_task_b = [(\"Random Forest\", rf), (\"XGBoost\", xgb)]\n",
        "# models_task_cde = [(\"Vanilla RNN\", best_rnn_model), (\"RNN with GloVe\", glove_rnn_model), (\"BiLSTM\", try3_model)]\n",
        "\n",
        "# for model_name, model in models_task_b:\n",
        "\n",
        "#     predictions = model.predict(x_tfidf_val)\n",
        "#     y_val_indices = y_val.argmax(axis=1)\n",
        "#     predictions_indices = predictions.argmax(axis=1)\n",
        "\n",
        "#     f1 = round(f1_score(y_val_indices, predictions_indices, average='macro'), 3)\n",
        "#     accuracy = round(accuracy_score(y_val_indices, predictions_indices), 3)\n",
        "\n",
        "#     print(f\"Model {model_name}:\")\n",
        "#     print(f\"Macro Avg F1 Score: {f1}\")\n",
        "#     print(f\"Validation Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# for model_name, model in models_task_cde:\n",
        "\n",
        "#     predictions = model.predict(x_glove_val)\n",
        "#     y_val_indices = y_val.argmax(axis=1)\n",
        "#     predictions_indices = predictions.argmax(axis=1)\n",
        "\n",
        "#     f1 = round(f1_score(y_val_indices, predictions_indices, average='macro'), 3)\n",
        "#     accuracy = round(accuracy_score(y_val_indices, predictions_indices), 3)\n",
        "\n",
        "#     print(f\"Model {model_name}:\")\n",
        "#     print(f\"Macro Avg F1 Score: {f1}\")\n",
        "#     print(f\"Validation Accuracy: {accuracy}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "564633ec",
      "metadata": {
        "id": "564633ec"
      },
      "outputs": [],
      "source": [
        "# best_model = try3_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ffc47e6",
      "metadata": {
        "id": "1ffc47e6"
      },
      "outputs": [],
      "source": [
        "# # untune able\n",
        "# embedding_dim = glove_dim\n",
        "# weight = [emb_matrix]\n",
        "# vocab_size = len(vocabulary)\n",
        "# n_classes = 3\n",
        "\n",
        "# #tune able\n",
        "# drop_rate = 0.2\n",
        "# batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9058c340",
      "metadata": {
        "id": "9058c340"
      },
      "outputs": [],
      "source": [
        "# def objective(trial):\n",
        "#     rnn_units = int(trial.suggest_categorical('rnn_units', [2**i for i in range(5, 9)]))\n",
        "#     learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
        "\n",
        "#     best_model = Sequential()\n",
        "#     best_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=weight, trainable=False))\n",
        "#     best_model.add(Bidirectional(LSTM(rnn_units, return_sequences=False), input_shape=(sequence_length, embedding_dim)))\n",
        "#     best_model.add(Dropout(drop_rate))\n",
        "#     best_model.add(Dense(n_classes, activation='softmax'))\n",
        "#     best_model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "#         loss='categorical_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "\n",
        "#     history_try3 = best_model.fit(x_glove_train, y_train, epochs=100, validation_data=(x_glove_val, y_val),\n",
        "#                                   batch_size=batch_size, callbacks=[early_stopping])\n",
        "\n",
        "#     acc = history_try3.history['val_accuracy'][-1]\n",
        "\n",
        "#     return acc\n",
        "\n",
        "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=6))\n",
        "# study.optimize(objective, n_trials=20, timeout=36000, n_jobs=-1, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcf311e",
      "metadata": {
        "id": "4bcf311e"
      },
      "outputs": [],
      "source": [
        "# best_params = study.best_params\n",
        "# best_params\n",
        "# 'rnn_units': 64, 'learning_rate': 0.0008752767781788608"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0bd61c",
      "metadata": {
        "id": "0b0bd61c"
      },
      "outputs": [],
      "source": [
        "# best_units = best_params['rnn_units']\n",
        "# best_learning_rate = best_params['learning_rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448b1243",
      "metadata": {
        "id": "448b1243"
      },
      "outputs": [],
      "source": [
        "# best_model1 = Sequential()\n",
        "# best_model1.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=weight, trainable=False))\n",
        "# best_model1.add(Bidirectional(LSTM(best_units, return_sequences=False),\n",
        "#                             input_shape=(sequence_length, embedding_dim)))\n",
        "# best_model1.add(Dropout(drop_rate))\n",
        "# best_model1.add(Dense(n_classes, activation='softmax'))\n",
        "# best_model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_learning_rate),\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# history_best = best_model1.fit(x_glove_train, y_train, epochs=100, validation_data=(x_glove_val, y_val), batch_size=batch_size,\n",
        "#                               callbacks = [early_stopping]\n",
        "#                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fa69195",
      "metadata": {
        "id": "8fa69195"
      },
      "outputs": [],
      "source": [
        "# y_pred_best = best_model1.predict(x_glove_val)\n",
        "# y_pred_classes_best = y_pred_best.argmax(axis=-1)  # For multi-class classification\n",
        "\n",
        "\n",
        "# report_best = classification_report(y_val.argmax(axis=-1), y_pred_classes_best, digits=3)\n",
        "# print(report_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25706605",
      "metadata": {
        "id": "25706605"
      },
      "source": [
        "Task F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed90978",
      "metadata": {
        "id": "bed90978"
      },
      "outputs": [],
      "source": [
        "# df_test = pd.read_csv('review_challenge.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4878b83",
      "metadata": {
        "id": "e4878b83"
      },
      "outputs": [],
      "source": [
        "# df_test['review_text'] = df_test['review_text'].str.replace(r'http\\S+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e6fc5d",
      "metadata": {
        "id": "d1e6fc5d"
      },
      "outputs": [],
      "source": [
        "# df_test['processed_text_review'] = df_test['review_text'].apply(\n",
        "#     lambda x: text_pre_process(x,lemmatising=True,stop_words = stop_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5db085",
      "metadata": {
        "id": "ee5db085"
      },
      "outputs": [],
      "source": [
        "# x_test = df_test['processed_text_review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703be3c3",
      "metadata": {
        "id": "703be3c3"
      },
      "outputs": [],
      "source": [
        "# for i in df_test['processed_text_review']:\n",
        "#   counter.update(tokenizer(i))\n",
        "\n",
        "# vocabulary_test = vocab(counter, min_freq=3)\n",
        "# vocabulary_test.set_default_index(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15c625e",
      "metadata": {
        "id": "a15c625e"
      },
      "outputs": [],
      "source": [
        "# len(vocabulary_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a03c3a",
      "metadata": {
        "id": "d8a03c3a"
      },
      "outputs": [],
      "source": [
        "# x_tokenized_test = sent_encode(x_test,vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ae2aae",
      "metadata": {
        "id": "b5ae2aae"
      },
      "outputs": [],
      "source": [
        "# sequence_length_test= np.max([len(s) for s in x_tokenized_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a61a32",
      "metadata": {
        "id": "e3a61a32"
      },
      "outputs": [],
      "source": [
        "# x_tokenized_test = [torch.tensor(sent, dtype=torch.long) for sent in x_tokenized_test]\n",
        "# x_encoded_test =padding(x_tokenized_test,sequence_length_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ad5045",
      "metadata": {
        "id": "c9ad5045"
      },
      "outputs": [],
      "source": [
        "# glove_dim = 300\n",
        "# vocab_lenth_test = len(vocabulary_test)\n",
        "# emb_matrix_test = np.zeros((vocab_lenth_test, glove_dim))\n",
        "\n",
        "# itos = vocabulary_test.get_itos()\n",
        "# for i, word in enumerate(itos):\n",
        "#   if word in glove_vac:\n",
        "#     emb_matrix_test[i] = glove_vac[word]\n",
        "#   else:\n",
        "#   # If a word is not in GloVe, you can initialize it with random values or zeros\n",
        "#     emb_matrix_test[i] = [0]*300\n",
        "\n",
        "# emb_matrix_test = torch.FloatTensor(emb_matrix_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8aa6c1",
      "metadata": {
        "id": "0a8aa6c1"
      },
      "outputs": [],
      "source": [
        "# predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b664d88",
      "metadata": {
        "id": "3b664d88"
      },
      "outputs": [],
      "source": [
        "# label_names = ['negative', 'neutral', 'positive']\n",
        "# predictions = best_model1.predict(x_encoded_test)\n",
        "# predicted_labels = [label_names[np.argmax(prediction)] for prediction in predictions]\n",
        "# df_test['airline_sentiment'] = predicted_labels\n",
        "# result_df = df_test[['review_id', 'airline_sentiment']]\n",
        "# result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27cdf163",
      "metadata": {
        "id": "27cdf163"
      },
      "outputs": [],
      "source": [
        "# df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c729a410",
      "metadata": {
        "id": "c729a410"
      },
      "outputs": [],
      "source": [
        "# result_df.to_csv('Group3_QBUS6850_2023S2.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
